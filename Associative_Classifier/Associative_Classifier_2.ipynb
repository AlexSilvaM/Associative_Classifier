{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97471bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'your_train_set.csv' #your train_set.csv\n",
    "\n",
    "df = pd.read_csv(df)\n",
    "\n",
    "numeric_columns = []\n",
    "integer_columns = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'float64':\n",
    "        numeric_columns.append(col)\n",
    "    elif df[col].dtype == 'int64':\n",
    "        integer_columns.append(col)\n",
    "        \n",
    "import pickle\n",
    "\n",
    "nome_do_arquivo_pickle = 'triselect.pickle'\n",
    "\n",
    "with open(nome_do_arquivo_pickle, 'rb') as f:\n",
    "    triselect = pickle.load(f)\n",
    "\n",
    "    \n",
    "n_classes=2 #number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bb440",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transactions_all.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "lines = content.strip().split('\\n')\n",
    "\n",
    "antecedents = []\n",
    "consequents = []\n",
    "\n",
    "for line in lines:\n",
    "    elements = line.split()\n",
    "    antecedents.append(' '.join(elements[:-1]))\n",
    "    consequents.append(elements[-1])\n",
    "\n",
    "rul = pd.DataFrame({\n",
    "    'antecedents': antecedents,\n",
    "    'consequents': consequents\n",
    "})\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def extract_rules_data(dataframe):\n",
    "    rules_dict = {}\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        antecedents = row['antecedents'].split()\n",
    "        consequent = row['consequents']\n",
    "\n",
    "        if consequent not in rules_dict:\n",
    "            rules_dict[consequent] = []\n",
    "        rules_dict[consequent].append(antecedents)\n",
    "\n",
    "    return rules_dict\n",
    "\n",
    "rules_data = extract_rules_data(rul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e16c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_rules(rules_data, numeric_columns, integer_columns):\n",
    "    result_dict = {}\n",
    "\n",
    "    for consequent, antecedents_list in rules_data.items():\n",
    "        classification_list = []\n",
    "\n",
    "        for antecedents in antecedents_list:\n",
    "            if all(element in numeric_columns for element in antecedents):\n",
    "                classification_list.append({'antecedents': antecedents, 'classification': 'N'})\n",
    "            elif all(element in integer_columns for element in antecedents):\n",
    "                classification_list.append({'antecedents': antecedents, 'classification': 'C'})\n",
    "            else:\n",
    "                classification_list.append({'antecedents': antecedents, 'classification': 'M'})\n",
    "\n",
    "        result_dict[list(consequent)[0]] = classification_list\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "resultrules = classify_rules(rules_data, numeric_columns, integer_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b0711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_triclusters(triselect, result):\n",
    "    selected_triclusters = {}\n",
    "\n",
    "    for key, antecedents_list in result.items():\n",
    "        key = int(key)  \n",
    "        selected_triclusters[key] = {}\n",
    "\n",
    "        for entry in antecedents_list:\n",
    "            antecedents = entry['antecedents']\n",
    "            classification = entry['classification']\n",
    "\n",
    "            selected_triclusters[key][tuple(antecedents)] = []\n",
    "\n",
    "            for tricluster_key, tricluster_df in triselect.items():\n",
    "                tricluster_columns = set(tricluster_df.columns)\n",
    "                moda = tricluster_df[' class'].mode()[0]\n",
    "                total_elementos = len(tricluster_df[' class'])\n",
    "                num_moda = (tricluster_df[' class'] == moda).sum()\n",
    "\n",
    "                if set(antecedents).issubset(tricluster_columns):\n",
    "                    selected_triclusters[key][tuple(antecedents)].append({\n",
    "                        'tricluster_key': tricluster_key,\n",
    "                        'tricluster_df': tricluster_df,\n",
    "                        'classification': classification,\n",
    "                        'ratio':num_moda/total_elementos\n",
    "                    })\n",
    "\n",
    "    return selected_triclusters\n",
    "\n",
    "\n",
    "selected_triclusters1 = select_triclusters(triselect, resultrules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d25f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_triclusters(selected_triclusters):\n",
    "    filtered_triclusters = {}\n",
    "\n",
    "    for key, antecedents_dict in selected_triclusters.items():\n",
    "        filtered_triclusters[key] = {}\n",
    "\n",
    "        for antecedents, triclusters_list in antecedents_dict.items():\n",
    "            filtered_triclusters[key][antecedents] = []\n",
    "\n",
    "            for tricluster in triclusters_list:\n",
    "                tricluster_df = tricluster['tricluster_df']\n",
    "                majority_class = tricluster_df[' class'].mode().values[0]\n",
    "\n",
    "               \n",
    "                key_as_int = int(key)\n",
    "\n",
    "               \n",
    "                if majority_class == key_as_int:\n",
    "                    filtered_triclusters[key][antecedents].append(tricluster)\n",
    "\n",
    "    return filtered_triclusters\n",
    "\n",
    "selected_triclusters = filter_triclusters(selected_triclusters1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_class(selected_triclusters):\n",
    "    filtered_triclusters = {}\n",
    "\n",
    "    for key, antecedents_dict in selected_triclusters.items():\n",
    "        filtered_triclusters[key] = {}\n",
    "\n",
    "        for antecedents, triclusters_list in antecedents_dict.items():\n",
    "            filtered_triclusters[key][antecedents] = []\n",
    "\n",
    "            for tricluster in triclusters_list:\n",
    "                tricluster_df = tricluster['tricluster_df']\n",
    "                target_class = tricluster['classification']\n",
    "\n",
    "               \n",
    "                key_as_int = int(key)\n",
    "\n",
    "               \n",
    "                filtered_df = tricluster_df[tricluster_df[' class'] == key_as_int]\n",
    "\n",
    "              \n",
    "                tricluster_copy = tricluster.copy()\n",
    "                tricluster_copy['tricluster_df'] = filtered_df\n",
    "                filtered_triclusters[key][antecedents].append(tricluster_copy)\n",
    "\n",
    "    return filtered_triclusters\n",
    "\n",
    "filtered_triclusters = filter_by_class(selected_triclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_columns(selected_triclusters):\n",
    "    modified_triclusters = {}\n",
    "\n",
    "    for key, antecedents_dict in selected_triclusters.items():\n",
    "        modified_triclusters[key] = {}\n",
    "\n",
    "        for antecedents, triclusters_list in antecedents_dict.items():\n",
    "            modified_triclusters[key][antecedents] = []\n",
    "\n",
    "            for tricluster in triclusters_list:\n",
    "                tricluster_df = tricluster['tricluster_df']\n",
    "                columns_to_keep = list(tricluster_df.columns)\n",
    "\n",
    "                \n",
    "                columns_to_remove = [col for col in columns_to_keep if col not in antecedents and col != 'X']\n",
    "                tricluster_df_modified = tricluster_df.drop(columns=columns_to_remove)\n",
    "\n",
    "               \n",
    "                tricluster_copy = tricluster.copy()\n",
    "                tricluster_copy['tricluster_df'] = tricluster_df_modified\n",
    "                modified_triclusters[key][antecedents].append(tricluster_copy)\n",
    "\n",
    "    return modified_triclusters\n",
    "\n",
    "modified_triclusters = remove_extra_columns(filtered_triclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_triclusters(modified_triclusters):\n",
    "    organized_triclusters = {}\n",
    "\n",
    "    for outer_key, inner_dict in modified_triclusters.items():\n",
    "        organized_triclusters[outer_key] = {}\n",
    "\n",
    "        for tuplo, triclusters_list in inner_dict.items():\n",
    "            for tricluster in triclusters_list:\n",
    "                classification = tricluster['classification']\n",
    "                tricluster_key = tricluster['tricluster_key']\n",
    "                tricluster_df = tricluster['tricluster_df']\n",
    "                ratio=tricluster['ratio']\n",
    "\n",
    "\n",
    "                new_key = (tuplo, classification)\n",
    "\n",
    "                if new_key not in organized_triclusters[outer_key]:\n",
    "                    organized_triclusters[outer_key][new_key] = []\n",
    "\n",
    "                organized_triclusters[outer_key][new_key].append({'tricluster_key': tricluster_key, 'tricluster_df': tricluster_df,'ratio':ratio})\n",
    "\n",
    "    return organized_triclusters\n",
    "\n",
    "triclusters_ready=organize_triclusters(modified_triclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RulesN(dictionary):\n",
    "    filtered_dict = {}\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        filtered_value = {sub_key: sub_value for sub_key, sub_value in value.items() if sub_key[1] == 'N'}\n",
    "        \n",
    "        if filtered_value:\n",
    "            filtered_dict[key] = filtered_value\n",
    "    \n",
    "    return filtered_dict\n",
    "\n",
    "\n",
    "rulesN = RulesN(triclusters_ready)\n",
    "rulesN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RulesM(dictionary):\n",
    "    filtered_dict = {}\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        filtered_value = {sub_key: sub_value for sub_key, sub_value in value.items() if sub_key[1] == 'M'}\n",
    "        \n",
    "        if filtered_value:\n",
    "            filtered_dict[key] = filtered_value\n",
    "    \n",
    "    return filtered_dict\n",
    "\n",
    "\n",
    "rulesM = RulesM(triclusters_ready)\n",
    "rulesM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RulesC(dictionary):\n",
    "    filtered_dict = {}\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        filtered_value = {sub_key: sub_value for sub_key, sub_value in value.items() if sub_key[1] == 'C'}\n",
    "        \n",
    "        if filtered_value:\n",
    "            filtered_dict[key] = filtered_value\n",
    "    \n",
    "    return filtered_dict\n",
    "\n",
    "\n",
    "rulesC = RulesC(triclusters_ready)\n",
    "rulesC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fef577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframes(rulesM, numeric_columns, integer_columns):\n",
    "    rulesMC = {}\n",
    "    rulesMN = {}\n",
    "\n",
    "    for key, value in rulesM.items():\n",
    "        rulesMC[key] = {}\n",
    "        rulesMN[key] = {}\n",
    "\n",
    "        for sub_key, tricluster_list in value.items():\n",
    "            rulesMC[key][sub_key] = []\n",
    "            rulesMN[key][sub_key] = []\n",
    "\n",
    "            for tricluster in tricluster_list:\n",
    "                tricluster_key = tricluster['tricluster_key']\n",
    "                tricluster_df = tricluster['tricluster_df']\n",
    "                ratio=tricluster['ratio']\n",
    "\n",
    "                \n",
    "                numeric_df = tricluster_df[tricluster_df.columns.intersection(integer_columns + ['X'])]\n",
    "                rulesMC[key][sub_key].append({'tricluster_key': tricluster_key, 'tricluster_df': numeric_df,'ratio':ratio})\n",
    "\n",
    "                \n",
    "                integer_df = tricluster_df[tricluster_df.columns.intersection(numeric_columns + ['X'])]\n",
    "                rulesMN[key][sub_key].append({'tricluster_key': tricluster_key, 'tricluster_df': integer_df,'ratio':ratio})\n",
    "    \n",
    "    new_rulesMN = {}\n",
    "\n",
    "    for key, value in rulesMN.items():\n",
    "        new_key = key\n",
    "        new_value = {}\n",
    "    \n",
    "        for inner_key, inner_value_list in value.items():\n",
    "            new_inner_key = (inner_key[0], 'MN')\n",
    "            new_inner_value_list = []\n",
    "\n",
    "            for inner_value in inner_value_list:\n",
    "                new_inner_value = {\n",
    "                    'tricluster_key': inner_value['tricluster_key'],\n",
    "                    'tricluster_df': inner_value['tricluster_df'],\n",
    "                    'ratio':inner_value['ratio']\n",
    "                }\n",
    "                new_inner_value_list.append(new_inner_value)\n",
    "\n",
    "            new_value[new_inner_key] = new_inner_value_list\n",
    "\n",
    "        new_rulesMN[new_key] = new_value\n",
    "        \n",
    "    new_rulesMC={}\n",
    "    for key, value in rulesMC.items():\n",
    "        new_key = key\n",
    "        new_value = {}\n",
    "    \n",
    "        for inner_key, inner_value_list in value.items():\n",
    "            new_inner_key = (inner_key[0], 'MC')\n",
    "            new_inner_value_list = []\n",
    "\n",
    "            for inner_value in inner_value_list:\n",
    "                new_inner_value = {\n",
    "                    'tricluster_key': inner_value['tricluster_key'],\n",
    "                    'tricluster_df': inner_value['tricluster_df'],\n",
    "                    'ratio':inner_value['ratio']\n",
    "                }\n",
    "                new_inner_value_list.append(new_inner_value)\n",
    "\n",
    "            new_value[new_inner_key] = new_inner_value_list\n",
    "\n",
    "        new_rulesMC[new_key] = new_value\n",
    "        \n",
    "    return new_rulesMC, new_rulesMN\n",
    "\n",
    "rulesMC, rulesMN = split_dataframes(rulesM, numeric_columns, integer_columns)\n",
    "\n",
    "rulesMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146442cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_jaccard_similarity(row1, row2):\n",
    "    list1 = list(row1.values[1:])  \n",
    "    list2 = list(row2.values[1:])  \n",
    "    \n",
    "    intersection = 0\n",
    "    union = len(list1)\n",
    "\n",
    "    for value1, value2 in zip(list1, list2):\n",
    "        if value1 == value2:\n",
    "            intersection += 1\n",
    "\n",
    "    jaccard_similarity = intersection / union if union != 0 else 0\n",
    "    return jaccard_similarity\n",
    "\n",
    "def calculate_average_jaccard_similarity(tricluster_df):\n",
    "    objects = tricluster_df['X'].unique()\n",
    "    pairs = list(combinations(objects, 2))\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for pair in pairs:\n",
    "        obj1, obj2 = pair\n",
    "        obj1_row = tricluster_df[tricluster_df['X'] == obj1].iloc[0]\n",
    "        obj2_row = tricluster_df[tricluster_df['X'] == obj2].iloc[0]\n",
    "\n",
    "        jaccard_similarity = calculate_jaccard_similarity(obj1_row, obj2_row)\n",
    "        similarities.append(jaccard_similarity)\n",
    "\n",
    "    if similarities:\n",
    "        average_similarity = sum(similarities) / len(similarities)\n",
    "    else:\n",
    "        average_similarity = 0\n",
    "\n",
    "    return average_similarity\n",
    "\n",
    "def calculate_and_assign_jaccard_similarity(rulesMCfit):\n",
    "    new_rulesMCfit = {}\n",
    "\n",
    "    for key, value in rulesMCfit.items():\n",
    "        new_key = key\n",
    "        new_value = {}\n",
    "\n",
    "        for inner_key, inner_value_list in value.items():\n",
    "            new_inner_key = (inner_key[0], 'MC')\n",
    "            new_inner_value_list = []\n",
    "\n",
    "            for inner_value in inner_value_list:\n",
    "                tricluster_key = inner_value['tricluster_key']\n",
    "                tricluster_df = inner_value['tricluster_df']\n",
    "                ratio=inner_value['ratio']\n",
    "\n",
    "                average_similarity = calculate_average_jaccard_similarity(tricluster_df)\n",
    "\n",
    "                new_inner_value = {\n",
    "                    'tricluster_key': tricluster_key,\n",
    "                    'tricluster_df': tricluster_df,\n",
    "                    'tol_min_por_cento': average_similarity,\n",
    "                    'ratio':ratio\n",
    "                }\n",
    "                new_inner_value_list.append(new_inner_value)\n",
    "\n",
    "            new_value[new_inner_key] = new_inner_value_list\n",
    "\n",
    "        new_rulesMCfit[new_key] = new_value\n",
    "\n",
    "    return new_rulesMCfit\n",
    "\n",
    "\n",
    "rulesMCfit2 = calculate_and_assign_jaccard_similarity(rulesMC)\n",
    "\n",
    "def remove_dictionaries_with_zero_tol(ruleMCfit2, min_threshold):\n",
    "    rulesMCfit = {}\n",
    "    for key, value in ruleMCfit2.items():\n",
    "        for sub_key, sub_value in value.items():\n",
    "            filtered_values = []\n",
    "            for item in sub_value:\n",
    "                if item['tol_min_por_cento'] > min_threshold:\n",
    "                    filtered_values.append(item)\n",
    "            if filtered_values:\n",
    "                if key not in rulesMCfit:\n",
    "                    rulesMCfit[key] = {}\n",
    "                rulesMCfit[key][sub_key] = filtered_values\n",
    "    return rulesMCfit\n",
    "\n",
    "\n",
    "rulesMCfit = remove_dictionaries_with_zero_tol(rulesMCfit2, 0)\n",
    "rulesMCfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_assign_jaccard_similarity(rulesMCfitu):\n",
    "    rulesMCfit = copy.deepcopy(rulesMCfitu)\n",
    "    new_rulesMCfit = {}\n",
    "\n",
    "    for key, value in rulesMCfit.items():\n",
    "        new_key = key\n",
    "        new_value = {}\n",
    "\n",
    "        for inner_key, inner_value_list in value.items():\n",
    "            new_inner_key = (inner_key[0], 'C')\n",
    "            new_inner_value_list = []\n",
    "\n",
    "            for inner_value in inner_value_list:\n",
    "                tricluster_key = inner_value['tricluster_key']\n",
    "                tricluster_df = inner_value['tricluster_df']\n",
    "                ratio=inner_value['ratio']\n",
    "\n",
    "                average_similarity = calculate_average_jaccard_similarity(tricluster_df)\n",
    "\n",
    "                new_inner_value = {\n",
    "                    'tricluster_key': tricluster_key,\n",
    "                    'tricluster_df': tricluster_df,\n",
    "                    'tol_min_por_cento': average_similarity,\n",
    "                    'ratio':ratio\n",
    "                }\n",
    "                new_inner_value_list.append(new_inner_value)\n",
    "\n",
    "            new_value[new_inner_key] = new_inner_value_list\n",
    "\n",
    "        new_rulesMCfit[new_key] = new_value\n",
    "\n",
    "    return new_rulesMCfit\n",
    "\n",
    "\n",
    "\n",
    "def remove_dictionaries_with_zero_tol(ruleMCfit2, min_threshold):\n",
    "    rulesMCfit = {}\n",
    "    for key, value in ruleMCfit2.items():\n",
    "        for sub_key, sub_value in value.items():\n",
    "            filtered_values = []\n",
    "            for item in sub_value:\n",
    "                if item['tol_min_por_cento'] > min_threshold:\n",
    "                    filtered_values.append(item)\n",
    "            if filtered_values:\n",
    "                if key not in rulesMCfit:\n",
    "                    rulesMCfit[key] = {}\n",
    "                rulesMCfit[key][sub_key] = filtered_values\n",
    "    return rulesMCfit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rulesCfit2 = calculate_and_assign_jaccard_similarity(rulesC)\n",
    "rulesCfit = remove_dictionaries_with_zero_tol(rulesCfit2, 0)\n",
    "rulesCfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_mean(df):\n",
    "    \n",
    "    df = df.drop(columns=['X'])\n",
    "    \n",
    "    mean_values = df.mean(axis=0)\n",
    "    return mean_values\n",
    "\n",
    "def calculate_means_in_rulesNtype(rulesN):\n",
    "    result = {}\n",
    "    for key, value in rulesN.items():\n",
    "        result[key] = {}\n",
    "        for condition, sub_dict in value.items():\n",
    "            result[key][condition] = []\n",
    "            for sub_item in sub_dict:\n",
    "                tricluster_key = sub_item['tricluster_key']\n",
    "                tricluster_df = sub_item['tricluster_df']\n",
    "                ratio=sub_item['ratio']\n",
    "                mean_values = calculate_mean(tricluster_df)\n",
    "                result[key][condition].append({'tricluster_key': tricluster_key, 'mean_values': mean_values,'ratio':ratio})\n",
    "    return result\n",
    "\n",
    "\n",
    "rulesNmean = calculate_means_in_rulesNtype(rulesN)\n",
    "rulesNmean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0867a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesMNmean = calculate_means_in_rulesNtype(rulesMN)\n",
    "rulesMNmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b350f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionar_coordenada_z(dicionario):\n",
    "    novo_dicionario = {}\n",
    "\n",
    "    for chave, valor in dicionario.items():\n",
    "        novo_valor = {}\n",
    "        for subchave, lista_valores in valor.items():\n",
    "            novo_item = []\n",
    "            for item in lista_valores:\n",
    "                novo_subitem = {}\n",
    "                novo_subitem['tricluster_key'] = item['tricluster_key']\n",
    "                novo_subitem['mean_values'] = {}\n",
    "                novo_subitem['ratio']=item['ratio']\n",
    "                for coluna, valor in item['mean_values'].items():\n",
    "                    partes_coluna = coluna.split('z')\n",
    "                    coordenada_z = int(partes_coluna[1])\n",
    "                    novo_subitem['mean_values'][coluna] = (valor, coordenada_z)\n",
    "                novo_item.append(novo_subitem)\n",
    "            novo_valor[subchave] = novo_item\n",
    "        novo_dicionario[chave] = novo_valor\n",
    "\n",
    "    return novo_dicionario\n",
    "\n",
    "\n",
    "\n",
    "rulesNmeanZ=adicionar_coordenada_z(rulesNmean)\n",
    "rulesMNmeanZ=adicionar_coordenada_z(rulesMNmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesNmeanZ\n",
    "#rulesMNmeanZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc33d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_por_y_e_z(dicionario):\n",
    "    novo_dicionario = {}\n",
    "\n",
    "    for chave, valor in dicionario.items():\n",
    "        novo_valor = {}\n",
    "        for subchave, lista_valores in valor.items():\n",
    "            novo_item = []\n",
    "            for item in lista_valores:\n",
    "                novo_subitem = {}\n",
    "                novo_subitem['tricluster_key'] = item['tricluster_key']\n",
    "                novo_subitem['ratio']=item['ratio']\n",
    "\n",
    "                grupos = {}\n",
    "                for coluna, (valor, z) in item['mean_values'].items():\n",
    "                    y = coluna.split('z')[0]\n",
    "                    if y not in grupos:\n",
    "                        grupos[y] = []\n",
    "                    grupos[y].append((coluna, (valor, z)))\n",
    "\n",
    "                for y, colunas in grupos.items():\n",
    "                    grupo = {}\n",
    "                    grupo.update({'mean_values': dict(colunas)})\n",
    "                    grupo['tolerancia'] = []  \n",
    "                    grupo['coef_ind'] = []  \n",
    "                    novo_subitem[y] = grupo\n",
    "\n",
    "                novo_item.append(novo_subitem)\n",
    "            novo_valor[subchave] = novo_item\n",
    "        novo_dicionario[chave] = novo_valor\n",
    "\n",
    "    return novo_dicionario\n",
    "\n",
    "\n",
    "rulesNmeanZgroup=agrupar_por_y_e_z(rulesNmeanZ)\n",
    "rulesMNmeanZgroup=agrupar_por_y_e_z(rulesMNmeanZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesNmeanZgroup\n",
    "#rulesMNmeanZgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf97000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_por_tricluster(rulesNmeanZgroup):\n",
    "    tricluster_dict_list = []\n",
    "    \n",
    "    for key, value in rulesNmeanZgroup.items():\n",
    "        for item_key, item_value in value.items():\n",
    "            for item in item_value:\n",
    "                tricluster_dict_list.append({key: {item_key: [item]}})\n",
    "    \n",
    "    return tricluster_dict_list\n",
    "\n",
    "\n",
    "rulesNlist = separar_por_tricluster(rulesNmeanZgroup)\n",
    "rulesMNlist = separar_por_tricluster(rulesMNmeanZgroup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesNlist\n",
    "#rulesMNlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variablesN(result):\n",
    "    variables = []\n",
    "    current_key = None\n",
    "    current_subkey = None\n",
    "    current_subkey_value = None\n",
    "    subkey_counter = {}\n",
    "    previous_key = None\n",
    "    previous_subkey_value = None\n",
    "    Y = 1\n",
    "\n",
    "    for d in result:\n",
    "        for key, value in d.items():\n",
    "            if current_key != key:\n",
    "                Y = 0\n",
    "\n",
    "            current_key = key\n",
    "            previous_key = key\n",
    "            for subkey, subvalue in value.items():\n",
    "                if subkey != current_subkey:\n",
    "                    Y += 1\n",
    "                    current_subkey = subkey\n",
    "                    current_subkey_value = subkey[0]  \n",
    "                    previous_subkey_value = current_subkey_value\n",
    "                for item in subvalue:\n",
    "                    tricluster_key = item['tricluster_key']\n",
    "                    variable_name = f'rulesN{current_key}{Y}{tricluster_key}'\n",
    "                    variables.append(variable_name)\n",
    "    return variables\n",
    "\n",
    "rulesNlistvar = create_variablesN(rulesNlist)\n",
    "\n",
    "def create_variablesMN(result):\n",
    "    variables = []\n",
    "    current_key = None\n",
    "    current_subkey = None\n",
    "    current_subkey_value = None\n",
    "    subkey_counter = {}\n",
    "    previous_key = None\n",
    "    previous_subkey_value = None\n",
    "    Y = 1\n",
    "\n",
    "    for d in result:\n",
    "        for key, value in d.items():\n",
    "            if current_key != key:\n",
    "                Y = 0\n",
    "\n",
    "            current_key = key\n",
    "            previous_key = key\n",
    "            for subkey, subvalue in value.items():\n",
    "                if subkey != current_subkey:\n",
    "                    Y += 1\n",
    "                    current_subkey = subkey\n",
    "                    current_subkey_value = subkey[0] \n",
    "                    previous_subkey_value = current_subkey_value\n",
    "                for item in subvalue:\n",
    "                    tricluster_key = item['tricluster_key']\n",
    "                    variable_name = f'rulesMN{current_key}{Y}{tricluster_key}'\n",
    "                    variables.append(variable_name)\n",
    "    return variables\n",
    "\n",
    "rulesMNlistvar = create_variablesMN(rulesMNlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ce23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesNlistvar\n",
    "#rulesMNlistvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variablesN(rulesNlist, rulesNlistvar):\n",
    "    \n",
    "    rulesN = []\n",
    "\n",
    "    \n",
    "    for i, var_name in enumerate(rulesNlistvar):\n",
    "        \n",
    "        globals()[var_name] = rulesNlist[i]\n",
    "        \n",
    "        \n",
    "        rulesN.append(var_name)\n",
    "    \n",
    "    return rulesN\n",
    "\n",
    "rulesNlistvar = create_variablesN(rulesNlist, rulesNlistvar)\n",
    "\n",
    "def create_variablesMN(rulesMNlist, rulesMNlistvar):\n",
    "    \n",
    "    rulesMN = []\n",
    "\n",
    "    \n",
    "    for i, var_name in enumerate(rulesMNlistvar):\n",
    "        \n",
    "        globals()[var_name] = rulesMNlist[i]\n",
    "        \n",
    "        \n",
    "        rulesMN.append(var_name)\n",
    "    \n",
    "    return rulesMN\n",
    "\n",
    "rulesMNlistvar = create_variablesMN(rulesMNlist, rulesMNlistvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def agrupar_variaveis(lista_variaveis):\n",
    "    \n",
    "    agrupadas = {}\n",
    "    \n",
    "    \n",
    "    padrao = r'(\\d+)tctri'\n",
    "    \n",
    "    for var in lista_variaveis:\n",
    "        \n",
    "        match = re.search(padrao, var)\n",
    "        if match:\n",
    "            sequencia = match.group(1)\n",
    "            \n",
    "            agrupadas.setdefault(sequencia, []).append(var)\n",
    "    \n",
    "    \n",
    "    lista_agrupada = list(agrupadas.values())\n",
    "    \n",
    "    return lista_agrupada\n",
    "\n",
    "rulesNlistlist = agrupar_variaveis(rulesNlistvar)\n",
    "rulesMNlistlist = agrupar_variaveis(rulesMNlistvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesNlistvar\n",
    "#rulesMNlistlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58124251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_listas(rulesNlistlist):\n",
    "    lista_de_variaveis = []\n",
    "    for lista in rulesNlistlist:\n",
    "        \n",
    "        indice_tctri = lista[0].find(\"tctri\")\n",
    "        if indice_tctri != -1:  \n",
    "            \n",
    "            nome_variavel = lista[0][:indice_tctri]\n",
    "            \n",
    "            globals()[nome_variavel] = lista\n",
    "            lista_de_variaveis.append(nome_variavel)\n",
    "    return lista_de_variaveis\n",
    "\n",
    "\n",
    "rulesNlistfit = criar_listas(rulesNlistlist)\n",
    "rulesMNlistfit = criar_listas(rulesMNlistlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesNlistfit\n",
    "#rulesMNlistfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_por_tricluster(rulesMCfitu):\n",
    "    rulesMCfit=copy.deepcopy(rulesMCfitu)\n",
    "    tricluster_dict_list = []\n",
    "\n",
    "    for key, inner_dict in rulesMCfit.items():\n",
    "        for nested_key, nested_value in inner_dict.items():\n",
    "            for item in nested_value:\n",
    "                tricluster_key = item['tricluster_key']\n",
    "                tricluster_dict = {\n",
    "                    key: {\n",
    "                        tricluster_key: {\n",
    "                            nested_key: [item]\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                tricluster_dict_list.append(tricluster_dict)\n",
    "\n",
    "    return tricluster_dict_list\n",
    "\n",
    "rulesMClist = separar_por_tricluster(rulesMCfit)\n",
    "rulesClist = separar_por_tricluster(rulesCfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465dd4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rulesClist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69428d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable_names(rulesMClist):\n",
    "    variable_names = []\n",
    "    prev_outer_key = None\n",
    "    prev_tricluster_key = None\n",
    "    counter = 1\n",
    "\n",
    "    for d in rulesMClist:\n",
    "        outer_key = list(d.keys())[0]\n",
    "        inner_key = list(d[outer_key].keys())[0]\n",
    "        tricluster_key = list(d[outer_key][inner_key].keys())[0]\n",
    "        \n",
    "        if prev_outer_key is None or outer_key != prev_outer_key:\n",
    "            counter = 1\n",
    "        elif tricluster_key != prev_tricluster_key:\n",
    "            counter += 1\n",
    "\n",
    "        var_name = f\"rulesMC{outer_key}{counter}{d[outer_key][inner_key][tricluster_key][0]['tricluster_key']}\"\n",
    "        variable_names.append(var_name)\n",
    "        \n",
    "        prev_outer_key = outer_key\n",
    "        prev_tricluster_key = tricluster_key\n",
    "\n",
    "    return variable_names\n",
    "\n",
    "rulesMClistvar = create_variable_names(rulesMClist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47783085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable_namesC(rulesMClist):\n",
    "    variable_names = []\n",
    "    prev_outer_key = None\n",
    "    prev_tricluster_key = None\n",
    "    counter = 1\n",
    "\n",
    "    for d in rulesMClist:\n",
    "        outer_key = list(d.keys())[0]\n",
    "        inner_key = list(d[outer_key].keys())[0]\n",
    "        tricluster_key = list(d[outer_key][inner_key].keys())[0]\n",
    "        \n",
    "        if prev_outer_key is None or outer_key != prev_outer_key:\n",
    "            counter = 1\n",
    "        elif tricluster_key != prev_tricluster_key:\n",
    "            counter += 1\n",
    "\n",
    "        var_name = f\"rulesC{outer_key}{counter}{d[outer_key][inner_key][tricluster_key][0]['tricluster_key']}\"\n",
    "        variable_names.append(var_name)\n",
    "        \n",
    "        prev_outer_key = outer_key\n",
    "        prev_tricluster_key = tricluster_key\n",
    "\n",
    "    return variable_names\n",
    "\n",
    "rulesClistvar = create_variable_namesC(rulesClist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00badf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesClistvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f02c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variables(rulesMClist, rulesMClistvar):\n",
    "    \n",
    "    rulesMC = []\n",
    "\n",
    "    \n",
    "    for i, var_name in enumerate(rulesMClistvar):\n",
    "        \n",
    "        globals()[var_name] = rulesMClist[i]\n",
    "        \n",
    "       \n",
    "        rulesMC.append(var_name)\n",
    "    \n",
    "    return rulesMC\n",
    "\n",
    "rulesMClistvar = create_variables(rulesMClist, rulesMClistvar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f790a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variablesC(rulesMClist, rulesMClistvar):\n",
    "    \n",
    "    rulesMC = []\n",
    "\n",
    "    \n",
    "    for i, var_name in enumerate(rulesMClistvar):\n",
    "        \n",
    "        globals()[var_name] = rulesMClist[i]\n",
    "        \n",
    "        \n",
    "        rulesMC.append(var_name)\n",
    "    \n",
    "    return rulesMC\n",
    "\n",
    "rulesClistvar = create_variablesC(rulesClist, rulesClistvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesMClistlist = agrupar_variaveis(rulesMClistvar)\n",
    "rulesClistlist = agrupar_variaveis(rulesClistvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesMClistfit = criar_listas(rulesMClistlist)\n",
    "rulesClistfit = criar_listas(rulesClistlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesMClistfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamarvar(listlistvar):\n",
    "    for rule in listlistvar:\n",
    "        variavel = globals()[rule]  \n",
    "        \n",
    "        return variavel\n",
    "        \n",
    "def chamarvarvar(variavel):\n",
    "    dic=[]\n",
    "    for rule in variavel:\n",
    "        variavel = globals()[rule]  \n",
    "        \n",
    "        dic.append(variavel)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39232e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_r_quadrado(x, y):\n",
    "    coeficientes = np.polyfit(x, y, 1)  \n",
    "    y_pred = np.polyval(coeficientes, x)\n",
    "    ss_total = np.sum((y - np.mean(y)) ** 2)\n",
    "    ss_res = np.sum((y - y_pred) ** 2)\n",
    "    r_quadrado = 1 - (ss_res / ss_total)\n",
    "    return r_quadrado\n",
    "\n",
    "def fit_polinomial(dicionario, grau_polinomio, toleranciau):\n",
    "    novo_dicionario = {}\n",
    "    \n",
    "    for chave, valor in dicionario.items():\n",
    "        novo_valor = {}\n",
    "        for subchave, lista_valores in valor.items():\n",
    "            novo_item = []\n",
    "            for item in lista_valores:\n",
    "                novo_subitem = {}\n",
    "                novo_subitem['tricluster_key'] = item['tricluster_key']\n",
    "                novo_subitem['ratio'] = item['ratio']\n",
    "                \n",
    "                for y, grupo in item.items():\n",
    "                    if y != 'tricluster_key' and y != 'ratio':\n",
    "                        coeficientes = {}\n",
    "                        mean_values = grupo['mean_values']\n",
    "                        x = [coord[1] for coord in mean_values.values()]\n",
    "                        y_values = [coord[0] for coord in mean_values.values()]\n",
    "                        \n",
    "                        coef = np.polyfit(x, y_values, grau_polinomio)\n",
    "                       \n",
    "                        if grau_polinomio == 1:\n",
    "                            coeficientes['a1'] = coef[0]\n",
    "                       \n",
    "                        else:\n",
    "                            for i in range(grau_polinomio):\n",
    "                                coeficientes[f'a{i+1}'] = coef[i]\n",
    "                        \n",
    "                        r_quadrado = calcular_r_quadrado(x, y_values)\n",
    "                        tolerancia = 1 - r_quadrado + toleranciau\n",
    "                        coeficientes['tolerancia'] = tolerancia  \n",
    "                        novo_subitem[y] = {'coeficientes': coeficientes}\n",
    "                \n",
    "                novo_item.append(novo_subitem)\n",
    "            novo_valor[subchave] = novo_item\n",
    "        novo_dicionario[chave] = novo_valor\n",
    "    \n",
    "    return novo_dicionario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamarvarfitpol(listlistvar):\n",
    "    for rule in listlistvar:\n",
    "        variavel = globals()[rule] \n",
    "        \n",
    "        chamarvarvarfitpol(variavel)\n",
    "        \n",
    "def chamarvarvarfitpol(variavel):\n",
    "    for rule in variavel:\n",
    "        nome_variavel = rule  \n",
    "        variavel_atual = globals()[rule]  \n",
    "        resultado = fit_polinomial(variavel_atual, 1, 0.2) #0.2 is the Tolerance LR parameter\n",
    "        globals()[nome_variavel] = resultado \n",
    "\n",
    "chamarvarfitpol(rulesNlistfit)\n",
    "chamarvarfitpol(rulesMNlistfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47a0b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = 'your_test_set.csv' #your test set .csv\n",
    "\n",
    "test = pd.read_csv(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70a707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "test[numeric_columns] = scaler.fit_transform(test[numeric_columns])\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extrair_lista_X(dataframe, resultrules,n_class):\n",
    "    listX = dataframe['X'].tolist()\n",
    "    listX1 = [[x, [[] for _ in range(n_class)]] for x in listX]\n",
    "    for i, lis in enumerate (listX1):\n",
    "        for j, lislis in enumerate (lis[1]):\n",
    "            for (key, value) in resultrules.items():\n",
    "                if int(key)==j:\n",
    "                    for d in value:\n",
    "                        if d['classification']=='N':\n",
    "                            listX1[i][1][int(key)].append([])\n",
    "                    for d in value:\n",
    "                        if d['classification']=='C':\n",
    "                            listX1[i][1][int(key)].append([])\n",
    "                    for d in value:\n",
    "                        if d['classification']=='M':\n",
    "                            listX1[i][1][int(key)].append([[],[]])\n",
    "                \n",
    "    return listX1\n",
    "\n",
    "\n",
    "\n",
    "class_results = extrair_lista_X(test, resultrules,n_classes)\n",
    "class_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5304f",
   "metadata": {},
   "source": [
    "## N e MN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61490be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_colunas_e_valores(dataset, rulesNmeanZgroup_fit):\n",
    "    testN = {}\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        key = row['X']\n",
    "        columns_values = {}\n",
    "        group_counter = {}\n",
    "\n",
    "        for rule_key, rule_values in rulesNmeanZgroup_fit.items():\n",
    "            rule_columns = []\n",
    "            for rule_index, rule in enumerate(rule_values):\n",
    "                if set(rule[0]) <= set(dataset.columns[1:-1]):\n",
    "                    rule_columns.extend(rule[0])\n",
    "                    group_counter[rule_key] = group_counter.get(rule_key, 0) + 1\n",
    "                    group_key = f\"{rule_key}{group_counter[rule_key]}\"\n",
    "                    values = {}\n",
    "                    for col in rule_columns:\n",
    "                        values[col] = row[col]\n",
    "                    columns_values[group_key] = values\n",
    "\n",
    "        testN[key] = columns_values\n",
    "\n",
    "    return testN\n",
    "\n",
    "testN = extrair_colunas_e_valores(test, rulesNmeanZgroup)\n",
    "testMN = extrair_colunas_e_valores(test, rulesMNmeanZgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a24774",
   "metadata": {},
   "outputs": [],
   "source": [
    "testN\n",
    "\n",
    "def remover_colunas_inteiras(testMN, integer_columns):\n",
    "    new_testMN = {}\n",
    "\n",
    "    for key, value in testMN.items():\n",
    "        new_value = {}\n",
    "        for sub_key, sub_value in value.items():\n",
    "            new_sub_value = {col: val for col, val in sub_value.items() if col not in integer_columns}\n",
    "            new_value[sub_key] = new_sub_value\n",
    "        new_testMN[key] = new_value\n",
    "\n",
    "    return new_testMN\n",
    "\n",
    "testMN = remover_colunas_inteiras(testMN, integer_columns)\n",
    "testMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c58ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionar_coordenada_z_testN(testN):\n",
    "    novo_testN = {}\n",
    "\n",
    "    for chave, grupos in testN.items():\n",
    "        novo_grupos = {}\n",
    "        for grupo_chave, colunas_valores in grupos.items():\n",
    "            novo_pontos = {}\n",
    "            for coluna, valor in colunas_valores.items():\n",
    "                partes_coluna = coluna.split('z')\n",
    "                coordenada_z = int(partes_coluna[1])\n",
    "                novo_pontos[coluna] = (valor, coordenada_z)\n",
    "\n",
    "            novo_grupos[grupo_chave] = novo_pontos\n",
    "\n",
    "        novo_testN[chave] = novo_grupos\n",
    "\n",
    "    return novo_testN\n",
    "\n",
    "testNz = adicionar_coordenada_z_testN(testN)\n",
    "testMNz = adicionar_coordenada_z_testN(testMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b360a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testNz\n",
    "#testMNz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38ff15",
   "metadata": {},
   "source": [
    "### N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2428b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def z_segundo_y(test):\n",
    "    testNz = copy.deepcopy(test)\n",
    "    new_dict = {}\n",
    "    \n",
    "    for key, value in testNz.items():\n",
    "        new_dict[key] = {}\n",
    "        for key2 in value.keys():\n",
    "            new_dict[key][key2] = {}\n",
    "            \n",
    "    for key, value in testNz.items():\n",
    "        for key2, value2 in value.items():\n",
    "            y_i=[]\n",
    "            for key3 in value2.keys():\n",
    "                padrao = r'y(.*?)z'\n",
    "                encontrados = re.findall(padrao, key3)\n",
    "                y_i.append(encontrados)\n",
    "            y_i_ok = sorted(list(set([valor[0] for valor in y_i])),key=int)\n",
    "            \n",
    "            for i in y_i_ok:\n",
    "                new_dict[key][key2][f\"y{i}\"] = {'fit': None, 'values': []}\n",
    "                \n",
    "                for key4, val4 in value2.items():\n",
    "                    encontrados2 = re.findall(padrao, key4)\n",
    "                    if encontrados2 and encontrados2[0] == i:\n",
    "                        new_dict[key][key2][f\"y{i}\"]['values'].append(val4)\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "testN = z_segundo_y(testNz)\n",
    "testMN=z_segundo_y(testMNz)\n",
    "#testMN\n",
    "testN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916566a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "def testfitN(testNu, n_classes, rulesNlistfitu):\n",
    "    testN = copy.deepcopy(testNu)\n",
    "    rulesNlistfit = copy.deepcopy(rulesNlistfitu)\n",
    "    testfit = []\n",
    "    \n",
    "\n",
    "    for xi_key, xi_value in testN.items():\n",
    "        testxi = []\n",
    "        testxi.append(xi_key)\n",
    "        x_ind = []\n",
    "\n",
    "        for item in rulesNlistfit:\n",
    "            x_ind.append(item[6])\n",
    "\n",
    "        x_ind = [int(x) for x in x_ind]\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            testxi.append([])\n",
    "\n",
    "        for i in range(len(x_ind)):\n",
    "            testxi[x_ind[i] + 1].append([])\n",
    "        for second_key in xi_value:\n",
    "            clatctri=[]\n",
    "            sk = second_key\n",
    "            for rule in rulesNlistfit:\n",
    "                if rule[len(\"rulesN\"):] == sk:\n",
    "                    selected_rule = rule\n",
    "            diclist = chamarvarvar(globals()[selected_rule])\n",
    "\n",
    "            for dic in diclist:\n",
    "                for key, value in dic.items():\n",
    "                    for y_key, y_value in value.items():\n",
    "                        cla=[]\n",
    "                        ratio=[]\n",
    "                        for y, coeficientes in y_value[0].items():\n",
    "                            if y=='ratio':\n",
    "                                ratio.append(coeficientes)\n",
    "                            if y != 'tricluster_key' and y != 'ratio':\n",
    "                                ai_tol = []\n",
    "                                for coef, val in coeficientes['coeficientes'].items():\n",
    "                                    ai_tol.append(val)\n",
    "                                fit_coefficients_list = []  \n",
    "                                y_values = [val[0] for val in testN[xi_key][sk][y]['values']]\n",
    "                                x_values = [val[1] for val in testN[xi_key][sk][y]['values']]\n",
    "\n",
    "                                \n",
    "                                fit_coefficients = np.polyfit(x_values, y_values, len(ai_tol)-1)\n",
    "\n",
    "                                \n",
    "                                fit_coefficients_without_constant = fit_coefficients[:-1]\n",
    "\n",
    "                                \n",
    "                                fit_coefficients_list.append(fit_coefficients_without_constant)\n",
    "                                \n",
    "                                for ii, co in enumerate(fit_coefficients_list[0]):\n",
    "                                    tol=ai_tol[-1]\n",
    "                                    val=co\n",
    "                                    valm=co+tol*co\n",
    "                                    valmn=co-tol*co\n",
    "                                    if ai_tol[ii]>=min(valm,valmn) and ai_tol[ii]<=max(valm,valmn):\n",
    "                                        cla.append(1)\n",
    "                                    else:\n",
    "                                        cla.append(0)\n",
    "                        \n",
    "                        clatctri.append(ratio[0]) if sum(cla) == len(cla) else clatctri.append(0)\n",
    "            testxi[int(sk[0])+1][int(sk[1:])-1].append(max(clatctri)) if sum(clatctri) > 0 else testxi[int(sk[0])+1][int(sk[1:])-1].append(0)\n",
    "            \n",
    "        testfit.append(testxi)\n",
    "        \n",
    "\n",
    "    organized_testNver = [[elemento[0], elemento[1:]] for elemento in testfit]                        \n",
    "    return organized_testNver\n",
    "\n",
    "testNver = testfitN(testN, n_classes, rulesNlistfit)\n",
    "testNver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def simplify_results(resultsu):\n",
    "    results = copy.deepcopy(resultsu)\n",
    "    for item in results:\n",
    "        for sublist in item[1]:\n",
    "            for i, subsublist in enumerate(sublist):\n",
    "                if isinstance(subsublist, list) and len(subsublist) == 1:\n",
    "                    sublist[i] = subsublist[0]\n",
    "    return results\n",
    "\n",
    "resultsf = simplify_results(testNver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def classificador(results_u, test_u):\n",
    "    results = copy.deepcopy(results_u)\n",
    "    test = copy.deepcopy(test_u)\n",
    "    total_objetos = len(test)\n",
    "    corretos = 0\n",
    "    empates = 0\n",
    "    empates_corretos = 0\n",
    "    empates_incorretos = 0\n",
    "    corretos_sem_empates = 0  \n",
    "    incorretos_sem_empates = 0  \n",
    "\n",
    "    \n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for ii, val in enumerate(results):\n",
    "        pontos_rec = []\n",
    "        max_pontos = []  \n",
    "        for ij, cla in enumerate(val[1]):\n",
    "            pontos = sum(cla)\n",
    "            max_pontos.append(len(cla))  \n",
    "            pontos_rec.append(pontos)\n",
    "\n",
    "        # Normalizando os pontos\n",
    "        pontos_normalizados = [p/max_pontos[idx] for idx, p in enumerate(pontos_rec)]\n",
    "\n",
    "       \n",
    "        max_pontos_norm = max(pontos_normalizados)\n",
    "        indices_max_pontos_norm = [i for i, j in enumerate(pontos_normalizados) if j == max_pontos_norm]\n",
    "\n",
    "        # Verificar se h empate\n",
    "        if len(indices_max_pontos_norm) > 1:\n",
    "            empates += 1\n",
    "            classe_predita = random.choice(indices_max_pontos_norm)\n",
    "        else:\n",
    "            classe_predita = indices_max_pontos_norm[0]\n",
    "\n",
    "        \n",
    "        classe_verdadeira = test.iloc[ii][' class']  \n",
    "        if classe_predita == classe_verdadeira:\n",
    "            corretos += 1\n",
    "            if len(indices_max_pontos_norm) == 1:  \n",
    "                corretos_sem_empates += 1\n",
    "        else:\n",
    "            if len(indices_max_pontos_norm) == 1:  \n",
    "                incorretos_sem_empates += 1\n",
    "        if len(indices_max_pontos_norm) > 1 and classe_verdadeira in indices_max_pontos_norm:\n",
    "                empates_corretos += 1\n",
    "        if len(indices_max_pontos_norm) > 1 and classe_verdadeira not in indices_max_pontos_norm:\n",
    "            empates_incorretos += 1\n",
    "\n",
    "       \n",
    "        true_labels.append(classe_verdadeira)\n",
    "        predicted_labels.append(classe_predita)\n",
    "\n",
    "    \n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    precisao = corretos / total_objetos\n",
    "    precisao_empates_corretos = (corretos_sem_empates + empates_corretos) / total_objetos  \n",
    "    precisao_empates_incorretos = (corretos_sem_empates) / total_objetos  \n",
    "\n",
    "    return precisao, empates, precisao_empates_corretos, precisao_empates_incorretos, conf_matrix\n",
    "\n",
    "\n",
    "resultados = classificador(resultsf, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_true_class(resultd, test_df):\n",
    "    result=copy.deepcopy(resultd)\n",
    "    for item in result:\n",
    "        object_name = item[0]\n",
    "        true_class = test_df[test_df['X'] == object_name][' class'].values[0]\n",
    "        item.append(true_class)\n",
    "    return result\n",
    "\n",
    "\n",
    "resultRF=add_true_class(resultsf, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a640316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def organize_data(resultRF):\n",
    "    \n",
    "    data = {'Pacients': [], 'True Class': []}\n",
    "    \n",
    "    \n",
    "    num_classes = len(resultRF[0][1])\n",
    "    \n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        data[f'Class {i} Rules'] = []\n",
    "    \n",
    "    \n",
    "    for item in resultRF:\n",
    "        pacient = item[0]\n",
    "        rules = item[1]\n",
    "        true_class = item[2]\n",
    "        \n",
    "        data['Pacients'].append(pacient)\n",
    "        data['True Class'].append(true_class)\n",
    "        \n",
    "        \n",
    "        for i, rule_list in enumerate(rules):\n",
    "            data[f'Class {i} Rules'].append(rule_list)\n",
    "    \n",
    "   \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "rfdf = organize_data(resultRF)\n",
    "rfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc5035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_dataframe(rfdf,t):\n",
    "    \n",
    "    data = {'Pacients': rfdf['Pacients'], 'True Classe': rfdf['True Class']}\n",
    "    \n",
    "    \n",
    "    sum_0 = []\n",
    "    sum_1 = []\n",
    "\n",
    "    for i in range(len(rfdf)):\n",
    "        sum_0.append(sum(float(val) for val in rfdf.loc[i, 'Class 0 Rules'] if float(val) >= t[0]))\n",
    "\n",
    "\n",
    "        sum_1.append(sum(float(val) for val in rfdf.loc[i, 'Class 1 Rules'] if float(val) >= t[1]))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    data['Sum 0'] = sum_0\n",
    "    data['Sum 1'] = sum_1\n",
    "    \n",
    "    \n",
    "    new_df = pd.DataFrame(data)\n",
    "    \n",
    "    \n",
    "    new_df['Norm 0'] = new_df['Sum 0'] / new_df['Sum 0'].sum()\n",
    "    new_df['Norm 1'] = new_df['Sum 1'] / new_df['Sum 1'].sum()\n",
    "    \n",
    "    \n",
    "    new_df['Predicted'] = new_df[['Norm 0', 'Norm 1']].idxmax(axis=1).str[-1].astype(int)\n",
    "    \n",
    "    \n",
    "    new_df['Ratio'] = (new_df['True Classe'] == new_df['Predicted']).astype(int)\n",
    "        \n",
    "    ratio_mean = new_df['Ratio'].sum() / len(new_df['Ratio'])\n",
    "    \n",
    "    return new_df,ratio_mean\n",
    "\n",
    "exp=process_dataframe(rfdf,[0,0]) #Choose the values that had the highest Mean of Ration columns that is obtained below.\n",
    "print(exp[1])\n",
    "exp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7484f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_values = [(i / 20, j / 20) for i in range(20) for j in range(20)]\n",
    "\n",
    "previous_mean = 0\n",
    "\n",
    "for t in t_values:\n",
    "    exp, ratio_mean = process_dataframe(rfdf, t)\n",
    "    if ratio_mean > previous_mean:\n",
    "        print(t)\n",
    "        print(\"Mean of Ratio column:\", ratio_mean)\n",
    "        print(\"\\n\")\n",
    "        previous_mean = ratio_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
