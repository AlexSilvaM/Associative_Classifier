{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230e6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = 'your_file.tsv' #Dataset .tsv file\n",
    "\n",
    "df = pd.read_csv(df,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bde159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_classes = df[' class'].nunique()\n",
    "\n",
    "contagem_por_classe = df[' class'].value_counts()\n",
    "\n",
    "porcentagens_por_classe = (contagem_por_classe / len(df[' class']))\n",
    "\n",
    "n_classes = df[' class'].nunique()\n",
    "print(f'There are {n_classes} classes')\n",
    "\n",
    "per_por_class = []  \n",
    "\n",
    "for classe, porcentagem in porcentagens_por_classe.items():\n",
    "    print(f'% {classe} is: {porcentagem:.2f}')\n",
    "    per_por_class.append(porcentagem)  \n",
    "\n",
    "print(per_por_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9af7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_columns = []\n",
    "integer_columns = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'float64':\n",
    "        numeric_columns.append(col)\n",
    "    elif df[col].dtype == 'int64':\n",
    "        integer_columns.append(col)\n",
    "print('float columns are:', numeric_columns)\n",
    "print('int columns are:', integer_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d48ba4",
   "metadata": {},
   "source": [
    "## Obtenção dos Triclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_arquivo = \"your_triclusters_output.txt\"  #The triclusters solution obtained from TCTriCluster .txt\n",
    "\n",
    "with open(nome_arquivo, 'r') as arquivo:\n",
    "    tctri = arquivo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0402df",
   "metadata": {},
   "outputs": [],
   "source": [
    "linhas = tctri.strip().split('\\n')\n",
    "\n",
    "tctriclass = []\n",
    "\n",
    "def calcular_classe_majoritaria(linha):\n",
    "    classes = [int(c) for c in linha.strip('[]').split(', ')]\n",
    "    total = len(classes)\n",
    "    classe_majoritária = max(set(classes), key=classes.count)\n",
    "    percentagem = (classes.count(classe_majoritária) / total)\n",
    "    return [classe_majoritária, percentagem, total]\n",
    "\n",
    "for linha in linhas:\n",
    "    resultado = calcular_classe_majoritaria(linha)\n",
    "    tctriclass.append(resultado)\n",
    "\n",
    "tctriclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem_por_classe = [sum(1 for item in tctriclass if item[0] == classe) for classe in range(n_classes)]\n",
    "\n",
    "porcentagens_por_classe = [contagem / len(tctriclass) * 100 for contagem in contagem_por_classe]\n",
    "\n",
    "for classe, porcentagem in enumerate(porcentagens_por_classe):\n",
    "    print(f'% of triclusters with the majority class {classe} is: {porcentagem:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tctri_classes, tctri_ratios, tctri_elements = zip(*tctriclass)\n",
    "\n",
    "bins = [i for i in range(0, 61, 10)]\n",
    "\n",
    "elements_binned = np.histogram(tctri_elements, bins=bins)[0]\n",
    "\n",
    "bin_labels = [f'{bins[i]}-{bins[i+1]-1}' for i in range(len(bins)-1)]\n",
    "\n",
    "plt.bar(bin_labels, elements_binned, color='r', edgecolor='black')\n",
    "\n",
    "plt.xlabel('Number of elements')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d4c2cd",
   "metadata": {},
   "source": [
    "### Filtragem dos Triclusters com o poder discriminativo threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db09c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecionar_triclusters_por_razao(tctriclass, min_razao):\n",
    "    selected_indices = []\n",
    "\n",
    "    for idx, (cls, ratio, elements) in enumerate(tctriclass):\n",
    "        if ratio >= min_razao:\n",
    "            selected_indices.append([idx,ratio])\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "min_razao = 0.6 #DS threshold parameter\n",
    "selected_indices = selecionar_triclusters_por_razao(tctriclass, min_razao)\n",
    "print(\"There were selected\", len(selected_indices), \"triclusters.\")\n",
    "selected_indices_modificado = [x[0] for x in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_triclusters(selected_indices, df, partes_XYZ_path):\n",
    "\n",
    "    with open(partes_XYZ_path, \"r\") as arquivo:\n",
    "        partes_XYZ = json.load(arquivo)\n",
    "\n",
    "    filtered_tctriclass = [tctriclass[idx] for idx in selected_indices]\n",
    "    tctri_classes, tctri_ratios, tctri_elements = zip(*filtered_tctriclass)\n",
    "\n",
    "    triclusters_selecionados = [{\"nome\": f\"tctri{i}\", \"info\": partes_XYZ[i]} for i in selected_indices]\n",
    "\n",
    "    triselect = {}\n",
    "\n",
    "    for i, tricluster in enumerate(triclusters_selecionados):\n",
    "        columns_to_keep = ['X']\n",
    "        nome_tricluster = tricluster['nome']\n",
    "        coordenadas_tricluster = tricluster['info']\n",
    "\n",
    "        for x, y, z in coordenadas_tricluster:\n",
    "            column_name = f'y{y}z{z}'\n",
    "            if column_name not in columns_to_keep:\n",
    "                columns_to_keep.append(column_name)\n",
    "\n",
    "        tctri_df = df[columns_to_keep].loc[df['X'].isin([f'x{x}' for x, _, _ in coordenadas_tricluster])]\n",
    "\n",
    "        tctri_df = pd.merge(tctri_df, df[['X', ' class']], on='X', how='left')\n",
    "\n",
    "        classe_majoritaria = tctri_df[' class'].mode().values[0]\n",
    "        total_elementos = len(tctri_df)\n",
    "        elementos_classe_majoritaria = len(tctri_df[tctri_df[' class'] == classe_majoritaria])\n",
    "        razao_classe_majoritaria = elementos_classe_majoritaria / total_elementos\n",
    "\n",
    "        tricluster_info = {'dataframe': tctri_df, 'ratio': razao_classe_majoritaria}\n",
    "        triselect[f'{nome_tricluster}'] = tricluster_info\n",
    "\n",
    "    return triselect\n",
    "\n",
    "partes_XYZ_path = 'partes_XYZ.txt'\n",
    "triselect1 = processar_triclusters(selected_indices_modificado, df, partes_XYZ_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_por_ratio_minimo(triselect, ratio_minimo):\n",
    "    triselect_filtrado = {}\n",
    "    for chave, valor in triselect.items():\n",
    "        if valor['ratio'] >= ratio_minimo:\n",
    "            triselect_filtrado[chave] = valor['dataframe']\n",
    "    return triselect_filtrado\n",
    "\n",
    "\n",
    "ratio_minimo = 0\n",
    "triselect = remover_por_ratio_minimo(triselect1, ratio_minimo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "nome_do_arquivo_pickle = 'triselect.pickle'\n",
    "\n",
    "with open(nome_do_arquivo_pickle, 'wb') as f:\n",
    "    pickle.dump(triselect, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125450b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_de_triclusters = len(triselect)\n",
    "print(\"Number of triclusters:\", numero_de_triclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def criar_dataset_especial(triselect, n_classes, n_scale):\n",
    "    dataset_especial = []\n",
    "    min_ratio = 1 / n_classes\n",
    "    scale_steps = (1 - min_ratio) / n_scale\n",
    "    \n",
    "    intervalos_repeticoes_i = {}\n",
    "    num_rep = []\n",
    "    for i in range(n_scale):\n",
    "        intervalo_inferior = min_ratio + i * scale_steps\n",
    "        intervalo_superior = min_ratio + (i + 1) * scale_steps - 0.000000000000001 if i < n_scale - 1 else 1.0\n",
    "        \n",
    "        num_repeticoes = int(2*i-1) if i > 0 else 1\n",
    "        intervalos_repeticoes_i[(intervalo_inferior, intervalo_superior)] = num_repeticoes\n",
    "        num_rep.append(num_repeticoes)\n",
    "    \n",
    "    for key, df in triselect.items():\n",
    "        intervalos_repeticoes = intervalos_repeticoes_i.copy()  \n",
    "        \n",
    "        num_elementos = len(df)\n",
    "        \n",
    "        if num_elementos <= 3:\n",
    "            for j, intervalo in enumerate(intervalos_repeticoes):\n",
    "                if j <= 3:\n",
    "                    intervalos_repeticoes[intervalo] = num_rep[0]\n",
    "                else:\n",
    "                    if len(num_rep) >= 2:\n",
    "                        intervalos_repeticoes[intervalo] = num_rep[1]\n",
    "                    else:\n",
    "                        intervalos_repeticoes[intervalo] = num_rep[0]\n",
    "        elif 4 <= num_elementos <= 5:\n",
    "            for j, intervalo in enumerate(intervalos_repeticoes):\n",
    "                if j <= 1:\n",
    "                    intervalos_repeticoes[intervalo] = num_rep[0]\n",
    "                elif 1 < j <= 3:\n",
    "                    if len(num_rep) >= 2:\n",
    "                        intervalos_repeticoes[intervalo] = num_rep[1]\n",
    "                    else:\n",
    "                        intervalos_repeticoes[intervalo] = num_rep[0]\n",
    "                else:\n",
    "                    if len(num_rep) >= 3:\n",
    "                        intervalos_repeticoes[intervalo] = num_rep[2]\n",
    "                    elif len(num_rep) >= 2:\n",
    "                        intervalos_repeticoes[intervalo] = num_rep[1]\n",
    "                    else:\n",
    "                        intervalos_repeticoes[intervalo] = num_rep[0]\n",
    "        \n",
    "        classe_maioritaria = df[' class'].mode().values\n",
    "        if len(classe_maioritaria) == 1:\n",
    "            ratio_classe_maioritaria = sum(df[' class'] == classe_maioritaria[0]) / len(df)\n",
    "            \n",
    "            for intervalo, num_repeticoes in intervalos_repeticoes.items():\n",
    "                if intervalo[0] <= ratio_classe_maioritaria <= intervalo[1]:\n",
    "                    colunas_especial = df.columns.tolist()\n",
    "                    if 'X' in colunas_especial:\n",
    "                        colunas_especial.remove('X')  \n",
    "                    if ' class' in colunas_especial:\n",
    "                        colunas_especial.remove(' class')  \n",
    "                    colunas_especial.append(str(classe_maioritaria[0]))  \n",
    "                    \n",
    "                    for _ in range(num_repeticoes):\n",
    "                        dataset_especial.append(colunas_especial)\n",
    "                    break\n",
    "    \n",
    "    dataset_especial = pd.DataFrame({'colunas': dataset_especial})\n",
    "    \n",
    "    return dataset_especial\n",
    "\n",
    "dataset_especial = criar_dataset_especial(triselect, n_classes, 5)\n",
    "dataset_especial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_arquivo = 'dataset_especial.txt'\n",
    "\n",
    "dataset_especial.to_csv(caminho_arquivo, index=False, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfpgrowth import find_frequent_patterns, generate_association_rules\n",
    "transactions = dataset_especial['colunas'].tolist()\n",
    "len(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transactions=[transaction for transaction in transactions]\n",
    "\n",
    "filename = \"transactions_all.txt\"\n",
    "with open(filename, 'w') as f:\n",
    "    for transaction in all_transactions:\n",
    "        f.write(' '.join(transaction) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
